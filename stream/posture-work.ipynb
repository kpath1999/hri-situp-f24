{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11684,"status":"ok","timestamp":1728154962978,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":240},"id":"sq2oz0GX2WBp","outputId":"01eaac2d-70cc-41dc-e3ee-71d737300dcb"},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","    !pip install opencv-python\n","    !pip install mediapipe\n","else:\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IazWDjxI4YK-"},"outputs":[],"source":["import cv2\n","import time\n","import math as m\n","import mediapipe as mp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMYw2Gk94msJ"},"outputs":[],"source":["# Initialize mediapipe selfie segmentation class\n","mp_pose = mp.solutions.pose\n","mp_holistic = mp.solutions.holistic"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XiUWJZd443SR"},"outputs":[],"source":["def findDistance(x1, y1, x2, y2):\n","    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n","    return dist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KcJFo5LF5Kla"},"outputs":[],"source":["def findAngle(x1, y1, x2, y2):\n","    theta = m.acos((y2-y1)*(-y1) / (m.sqrt((x2-x1)**2 + (y2-y1)**2)*y1))\n","    degree = int(180/m.pi)*theta\n","    return degree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIrWvZ1z53RI"},"outputs":[],"source":["def sendWarning(x):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GbsWTCoS6I6G"},"outputs":[],"source":["# Initialize frame counters\n","good_frames = 0\n","bad_frames = 0\n","\n","# Font type\n","font = cv2.FONT_HERSHEY_SIMPLEX\n","\n","# Colors\n","blue = (255, 127, 0)\n","red = (50, 50, 255)\n","green = (127, 255, 0)\n","dark_blue = (127, 20, 0)\n","light_green = (127, 233, 100)\n","yellow = (0, 255, 255)\n","pink = (255, 0, 255)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786,"status":"ok","timestamp":1728154975729,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":240},"id":"KS1iKcnw6zW8","outputId":"fd68f5a3-15c3-4e22-e8d4-f2a94613c0f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3Mw_fgj6a0Q"},"outputs":[],"source":["# Initialize mediapipe pose class\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose()\n","\n","# Initialize video capture object\n","file_name = '/content/drive/My Drive/MSCS/HRI/videos/kausar-posture-input.mp4'\n","cap = cv2.VideoCapture(file_name)\n","\n","# Meta\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","frame_size = (width, height)\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","\n","# Initalize video writer\n","video_output = cv2.VideoWriter('/content/drive/My Drive/MSCS/HRI/videos/kausar-posture-output.mp4', fourcc, fps, frame_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1728154976370,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":240},"id":"9TBBkWQs8XtT","outputId":"ef2925ee-c684-4b74-8d3f-ba6f6466ab9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Status: 30 1280 720 (1280, 720) 1983148141\n"]}],"source":["print(\"Status:\", fps, width, height, frame_size, fourcc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1728154976370,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":240},"id":"Zcvofo1n8mMO","outputId":"c16a3672-4474-4018-ef2e-00e611185e77"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nwhile cap.isOpened():\\n    # Capture frames.\\n    success, image = cap.read()\\n    if not success:\\n        print(\"Null.Frames\")\\n        break\\nprint(\"check finished\")\\ncap.release()\\n'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","while cap.isOpened():\n","    # Capture frames.\n","    success, image = cap.read()\n","    if not success:\n","        print(\"Null.Frames\")\n","        break\n","print(\"check finished\")\n","cap.release()\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43212,"status":"ok","timestamp":1728155019572,"user":{"displayName":"Kausar Patherya","userId":"09012208137279792936"},"user_tz":240},"id":"nJbkfOWY7spB","outputId":"1be467cb-4185-4626-83cd-c6fab1fac822"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing..\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n","  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"]},{"name":"stdout","output_type":"stream","text":["Null.Frames\n","Finished.\n"]}],"source":["print('Processing..')\n","while cap.isOpened():\n","    # Capture frames.\n","    success, image = cap.read()\n","    if not success:\n","        print(\"Null.Frames\")\n","        break\n","    # Get fps.\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    # Get height and width.\n","    h, w = image.shape[:2]\n","\n","    # Convert the BGR image to RGB.\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    # Process the image.\n","    keypoints = pose.process(image)\n","\n","    # Convert the image back to BGR.\n","    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","\n","    # Use lm and lmPose as representative of the following methods.\n","    lm = keypoints.pose_landmarks\n","    lmPose = mp_pose.PoseLandmark\n","\n","    # Acquire the landmark coordinates.\n","    # Once aligned properly, left or right should not be a concern.\n","    # Left shoulder.\n","    l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n","    l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n","    # Right shoulder\n","    r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n","    r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n","    # Left ear.\n","    l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n","    l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n","    # Left hip.\n","    l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n","    l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n","\n","    # Calculate distance between left shoulder and right shoulder points.\n","    offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n","\n","    # Assist to align the camera to point at the side view of the person.\n","    # Offset threshold 30 is based on results obtained from analysis over 100 samples.\n","    if offset < 100:\n","        cv2.putText(image, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n","    else:\n","        cv2.putText(image, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n","\n","    # Calculate angles.\n","    neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n","    torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n","\n","    # Draw landmarks.\n","    cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n","    cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n","\n","    # Let's take y - coordinate of P3 100px above x1,  for display elegance.\n","    # Although we are taking y = 0 while calculating angle between P1,P2,P3.\n","    cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n","    cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n","    cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n","\n","    # Similarly, here we are taking y - coordinate 100px above x1. Note that\n","    # you can take any value for y, not necessarily 100 or 200 pixels.\n","    cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n","\n","    # Put text, Posture and angle inclination.\n","    # Text string for display.\n","    angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))\n","\n","    # Determine whether good posture or bad posture.\n","    # The threshold angles have been set based on intuition.\n","    if neck_inclination < 40 and torso_inclination < 10:\n","        bad_frames = 0\n","        good_frames += 1\n","\n","        cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n","        cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n","        cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n","\n","        # Join landmarks.\n","        cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n","        cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n","        cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n","        cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n","\n","    else:\n","        good_frames = 0\n","        bad_frames += 1\n","\n","        cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n","        cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n","        cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n","\n","        # Join landmarks.\n","        cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n","        cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n","        cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n","        cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n","\n","    # Calculate the time of remaining in a particular posture.\n","    good_time = (1 / fps) * good_frames\n","    bad_time =  (1 / fps) * bad_frames\n","\n","    # Pose time.\n","    if good_time > 0:\n","        time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'\n","        cv2.putText(image, time_string_good, (10, h - 20), font, 0.9, green, 2)\n","    else:\n","        time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'\n","        cv2.putText(image, time_string_bad, (10, h - 20), font, 0.9, red, 2)\n","\n","    # If you stay in bad posture for more than 3 minutes (180s) send an alert.\n","    if bad_time > 180:\n","        sendWarning()\n","    # Write frames.\n","    video_output.write(image)\n","print('Finished.')\n","cap.release()\n","video_output.release()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP7NcdXeNfwRyn7tEz9mqgH","provenance":[]},"kernelspec":{"display_name":"cv_proj0","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
